- to understand what a dlh is, we need to understand:
## History of data management and analytics
- in 1980, the need to make data driven decision rose
	- this meant, orgs need to move away from relational dbs in search of a system that can manage and analyze data that is generated at high volumes and speed
- dwh was designed to collect and consolidate data with the following pros:
	- BI, Analytics, Structured & clean data, predefined schemas
	- but also with the following cons:
		- no support for semi- or unstructured data(less support for data variety)
		- inflexible schemas
		- struggled with volume and velocity upticks
		- long processing time
- early 2000s, advent of BD drove the development of data lakes
	- where all varieties of data can live together and be collected at high speeds and volumes
	- pros: flexible data storage, streaming support, cost efficient in the cloud, support for AI and ML
	- cons: lacked what dwhs offered
		- no txnal support
		- poor data reliability (mostly due to various formats)
		- cant enforce data quality
		- slow analysis performance 
		- data governance concerns(security challenges due to unstructured nature), dwhs were still needed
- because DL did not replace DWH completely for reliable bi, orgs constructed complex tech stack envs: dwh+dl+systems for streaming, time-series and graph data
	- complexity, delays and silos were the results
	- data had to be copied bw systems and sometimes were needed to be copied back
	- same info stored twice
	- disjointed systems meant successful AI implementations were difficult
	- value behind the data was lost
- orgs needed a single pf that can support all apps including SQL analytics to ML 
![[Pasted image 20240210083612.png]]

- a new data management architecture to tackle all the above problems and requirements: DLH
- open arch: combining best of both worlds
	- built on a dl
![[Pasted image 20240210084206.png]]
- pros:
	- transaction support for concurrent read-write interactions
	- schema enforcement and governance for data integrity and robust auditing needs
	- DG to support privacy regulations and data use metrics
	- BI support to reduce latency bw obtaining data and drawing insights
	- decoupled storage from compute
	- open storage formats(like parquet), so variety of tools can access the data directly and efficiently
	- support for diverse data types(all diff data)
	- support for diverse wls
		- SQL, ML, DS etcs
	- end-to-end streaming for real time reports
- supports work for DA,DE and Data Scientists in one location
- DLH: modernized dwh with the flexibility of a data lake