#### Multi-col indexes
- indexes discussed so far only ***map a single key*** to a value
	- not sufficient if we need to ***query multiple columns or fields***
- the most common type of multi-col index is called a ***concatenated index***
	- combines several fields into one key by appending one col to another
	- the ***order*** in which fields are combined are ***important***
	- ex: last_name, first_name combination pointing to a phone number
	- this index can be used to find all the people with a particular last name, or with particular last name and first name
	- useless if we need to find with only first name
- multi-col index can also be called as ***multi-dimensional indexes***
- multi-dim indexes are a more general way of ***querying several cols at once***
- in the query like the following, a std bt or LSMT index is not able to answer efficiently
![[Pasted image 20240311190428.png]]
- those indexes can give us either all the restros in a range of latitudes(but at any longitude) or vice versa, but not both simultaneously
- one option to deal with multi-dim index requirement is to convert them into one number
	- this type of index was not explained in detail in the book

#### full-text search and fuzzy indexes
- all the indexes discussed so far assume that we have ***exact data*** and allows us to query for exact values of a key or a sortable range of keys
- they do not allow us to search for ***similar keys***, such as misspelled words
	- this is called ***fuzzy querying*** and it requires different techniques of indexing
- ex: full text search engines commonly allow a search :
	- for one word to be expanded to include synonyms of the word
	- by ignoring grammatical variations of words
	- occurrences of words near each other in the same doc
- edit distance: ED of 1 means that one letter has been added, removed or replaced
	- querying tech have their limitations on ED while searching

#### Keeping everything in memory
- compared to main mem, disks are awkward to deal with
- with both ***magnetic disks and ssds***, we need to be careful about ***how the data is laid out***
	- this affects our performance on reads and writes
- the drawbacks of disks are tolerated because of two significant advantages
	- they are durable
	- low cost per gb
		- but now RAMs are becoming cheaper
- since many datasets are not so big, it is feasible to keep them ***entirely in memory***
	- distributed ***across machines***
	- this led to the development of in-mem dbs
- some in-mem kvS are intended for caching ***use only***
	- means we are okay with data being lost, in case of restart
- but some in-mem dbs aim for durability
	- using special hw(such as battery powered RAM)
	- by writing a log of changes to disk
	- writing periodic ss to disk
	- replicating the in-mem state to other machines
- restart forces to reload state
	- either from disk or over the nw from a replica(unless special hw is used)
- even though a write to disk happens, these are still in-mem dbs
	- as ***reads are served purely from mem***
	- writing to disks have other advs: files on disk can easily backed up, inspected, and analyzed by external utilities
- in-mem dbs are not fast because ***they avoid reading from disk***
	- why?
		- even in normal dbs, if our mem is big enough, the data is cached in memory
			- in that case we serve directly from mem
	- the main reason for speed is that we can ***avoid encoding*** in-mem ds in a form that can be written to disk