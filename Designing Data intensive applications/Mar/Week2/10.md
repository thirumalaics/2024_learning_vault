#### Downsides of LSMT
- response time of queries to log-structured storage engines can be high ***at high percentiles*** of requests
	- BTrees are more ***predictable***, because overwrites happen then and there
	- ***compaction process*** can sometimes ***interfere*** with the performance of ***ongoing reads and writes***
	- storage engines try to perform ***compaction incrementally***, without affecting concurrent access
		- but even then, the ***impact*** is observed because disks have ***limited resources***
		- the impact is that a request needs to ***wait*** until the disk finishes an expensive compaction operation and some bw is freed up
		- the impact is small in normal cases
		- this disk bw is for both write and read
- disk's finite ***write bandwidth*** needs to be ***shared*** between
	- the initial write (logging and flushing a ***memtable*** to disk) 
	- the compaction threads running in the background
		- when writing to an empty db, the full disk bw can be used for the ***initial write***
		- bigger the db, ***more disk bw for compaction***
- if the incoming write throughput is high and compaction is not configured carefully, at a point ***compaction cannot keep up***
	- num of unmerged segments on disk keeps ***growing*** until disk space runs out
	- read takes more time because of this
		- because ***more files*** to be checked
	- usually SST-based storage engine do ***not restrict write reqs***
		- so we have to ***explicitly monitor*** the (reqs and compaction) to detect this problem
	- even with one hash map for a file it may get difficult.
		- especially if the hash map's keys are sparse
- an adv in Btree: ***one key stored in one place in the index***
	-  in LSMT, one key may be in many segments
		- but how is this a disadv?
			- is it a storage disadv or what?
		- if not how is this a disadv?
			- even though the keys are stored in many places, only the key in most recent segment is considered for operations right?s
			- may be this
	- Btree attractive for strong txnal semantics because of this feature
		- in many rdbs, ***txn isolation*** is implemented using locks on range of keys
		- in btree, these locks can be ***directly attached to tree***
			- ~~~~ CH7
- btrees are established in many dbs
- BT provide ***consistent good performance*** for many wls
- in new datastores, LSMT are used more
- to decide on which one suits us, ***test empirically***

## Other Indexing Structures
- so far, kvps were discussed
	- similar to ***PK index*** in the RM
	- each key is associated with only one value
	- no multiple matches
	- each key is unique
- secondary indexes are common
	- ***secondary indexes*** can be constructed from a kv index
	- keys are not unique
		- this can be solved in two ways:
			- key points to a list of matching row identifiers
			- make each key unique by appending a row identifier to it
	- both LSMT and BT can be used as secondary indexes

### Storing Values within the index
- the key in an index is searched for by queries
- value can be one of two things in the index: 
	- actual row(doc or vertex)
	- reference to the row stored elsewhere
- in the second case, the place where rows are stored is a ***heap file***
	- it stores data in ***no particular order***
- heap file approach is common because it ***avoids duplication***
	- especially when secondary indexes are present
	- actual data stored in one place
- when ***updating a value without changing the key***, the heap file approach can be ***efficient***
	- the record ***can be overwritten*** in place
		- as long as the new value size is < old value
	- this saves us the effort of re-pointing and changing the reference in the index
	- if new value is large, the key needs to be ***moved*** to a new place in the heap where there is enough space
		- then ***all indexes*** should point to the new loc for the record
		- or the old heap location can have a ***forwarding pointer***
- extra hop from index to heap file may be costly for some use cases, for that case the ***row is stored within the index***
	- aka clustered index
	- in mysql innodb storage engine, PKI is always a CI
- a compromise bw NCI and CI is called as ***covering index or index with included cols***
	- index stores some columns of the table
	- some queries are answered by the index alone
		- the index is said to ***cover the query***
- as with any kind of duplication of data, clustered and covering indexes can speed up read
	- they require more storage
	- can add overhead on writes
	- db need to go to additional effort to enforce txnal guarantees
		- bcos apps should not see inconsistencies due to dups