## CDC
- what is sequence by in APPLY CHANGES INTO?
	- handles scenarios where multiple edits, such as updates or deletes are associated with the same primary key
- What is COLUMNS \*?
	- specifies list of fields that must be added to the target table, where we can exclude audit columns
- what are the prerequisites for using APPLY CHANGES INTO command?
	- the target DLT table must exist b4 execution of this command
- what are the features of APPLY CHANGES INTO command?
	- automatically orders late arriving records using the user-provided sequencing key
		- if any records arrive out of order, downstream system result can be properly re-computed to reflect the updates
		- I am not sure what do they mean by this
	- default assumption is that rows will contain inserts and updates
	- we can optionally apply deletes (APPLY AS DELETE WHEN condition)
	- specify one or many fields as the PK for a table
	- specify columns to ignore, with the except keyword
	- support applying changes as SCD Type 1(default) or SCD type 2
		- apply changes into command defaults to creating a type 1 slowly changing dimension
			- as it updates the existing record
- what are the cons of the APPLY CHANGES INTO command?
	- breaks the append only requirements for streaming table sources
		- we cannot use this as source
- change captured in the table comes with row_status(indicating insert, update or delete)
- can an existing pipeline be edited to add another notebook?
	- yes
	- click on settings and click on add notebook libraries, this will add another nb to be referenced by our pipeline
	- we can then click start to run our updated pipeline
	- if we have any issues running the pipeline, we click on `full refresh all`
		- clears all data from each table and load data freshly

- ```APPLY CHANGES INTO LIVE.silver_table FROM STREAM(LIVE.bronze_table) KEYS (book_id) APPLY AS DELETE WHEN row_status = "DELETE" SEQUENCE BY row_time COLUMNS * EXCEPT(row_status, row_time);```
- the above silver table can no longer be used as a streaming source, but it can be used as a DELTA LIVE TABLE
	- this means, the following query will work fine:
```
CREATE LIVE TABLE author_counts_state
COMMENT "Number of books"
AS SELECT author, counts(*) FROM LIVE.silver_table
group by author
```
- what is the difference between live tables and STREAMING TABLES?
- can we define DLT Views?
	- yes
	- ```CREATE LIVE VIEW book_sales AS SELECT * FROM ();```
	- DLT VIEWs are temp views scoped to the current **DLT pipeline**
	- not persisted to metastore
- can views be used to enforce data quality?
	- yes and metrics are reported for views as well
- can tables and views defined in another notebook be referenced in the current nb?
	- yes, as DLT supports scheduling multiple nbs as part of a single DLT pipeline
	- the scope of schema referenced by the LIVE keyword is at the DLT pipeline level rather than the notebook level
	- this allows tables defined in another nb within the same pp to be referenced in the current nb