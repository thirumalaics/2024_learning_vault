- sparksql has built in functionality to directly interact with JSON data stored as strings
	- col:key1:nested_key1
	- when trying to access non-existent key, the result is null
		- in the below picture, name column does not exist within the column profile
	- ![[Pasted image 20240719091706.png]]
- sparksql also has the ability to parse JSON objects into struct types
	- struct is a native spark type with nested attributes
	- using the [from_json](https://docs.databricks.com/en/sql/language-manual/functions/from_json.html) function
	- takes 3 args, 1 optional
	- ![[Pasted image 20240719092442.png]]
	- schema of a json, can be derived from a single row value using `schema_of_json` function
	- ![[Pasted image 20240719093006.png]]
	- this function does not access column as an argument
	- takes a json string as argument, along with one optional argument
	- ![[Pasted image 20240719093230.png]]
	- with struct type's nested columns, we can interact using . notation
- the following syntax flattens the top most struct into columns
	- address struct is not flattened(address is a column in the details struct with type struct)
- ![[Pasted image 20240719093704.png]]
- magic commands have be the topmost command in a cell to have any effect
	- no other statement should be above the magic command in the cell
- `SELECT books[0].* from orders;`(in this case, books column is an array of structs)
	- this statement errored out
	- I was trying to unnest the columns of struct inside an array
	- but books\[0\]  displayed the first element of the array
	- `SELECT book[0].book_id from orders;`
		- where as this worked
	- `SELECT books.book_id from orders;`
		- this also worked, displaying book_id file for all elements of the array
		- ![[Pasted image 20240719095016.png]]
	- `SELECT books.* from orders`
		- this errored out saying that \* can only expand struct data types
- collect_set function allows us to collect unique values for a field, including fields within an array
	- output is an array
	- ![[Pasted image 20240719095254.png]]
- flatten function can be used to flatten list of list into list
- array_distinct function only results unique elements of an array
- ![[Pasted image 20240719095932.png]]
- pivot function supported in spark sql
	- practice pivot
- what is anti join and semi join