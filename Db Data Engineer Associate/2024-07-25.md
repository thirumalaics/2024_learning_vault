- how are auto loader's operation on the table recorded in the version history of a table?
	- new files added to the location of autoloader query is treated as STREAMING UPDATE
		- in the version history table, each new file that is added creates a new version of the table and the operation column has the value STREAMING UDPATE

## Multi hop arch
- what is mult-hop architecture?
	- aka medallion architecture
	- it is a data design pattern used to logically organize data in multi-layered approach
	- incrementally improving the ***structure and quality*** of data as it flows through each layer of the architecture
- What are the layers of multi-hop architecture?
	- usually consists of three layers
		- bronze, silver and gold
- Describe bronze layer
	- bronze tables consists of raw data ingested from various sources
		- like json files, operational databases, or Kafka stream
- Describe silver layer
	- silver table provides more refined view of our data
	- data can be cleaned and filtered at this level
		- enriched by joining with other tables
- Describe gold layers
	- layer in the architecture where tables that provide the following are present
		- business level aggs, often used for reporting and dashboarding or even for machine learning
- benefits of MHA:
	- simple data model
	- enables incremental ETL
	- combine streaming and batch workloads in unified pipeline
	- recreation of tables from raw data any time is possible



##### does streaming read and/or auto loader read continuously run?
- no both stream read and auto loader read operation alone do not run continuously
- only when they are written or queried, they continuously run
- this is proved in MHA notebook
##### is auto-loader used only for incremental data loading from files to tables?
- in the video on MHA hands on, he created a temp view on top of a streaming reach configured with auto loader options
- so there was no write involved
- how is this different from a normal parquet file stream read and creating a temp view on top it?
- the following is the code that the guy ran:
```
spark.readStream.format('cloudFiles')
.option('cloudFiles.format','parquet')
.option('cloudFiles.schemaLocation','xys')
.load('path')
.createOrReplaceTempView('view_name')
```
- the streaming query became active as soon as he queried the temp view
- we can create a temp view on top of this temp view, this does not start the streaming query
##### how is auto loader different from a normal streaming read?
- when I tried creating a normal streaming dataframe on a parquet file directory:
	- `spark.readStream.format("parquet").load(f'{dataset_bookstore}/orders-raw')`
	- an error was thrown saying that when a streaming source dataframe is created, schema must be specified






