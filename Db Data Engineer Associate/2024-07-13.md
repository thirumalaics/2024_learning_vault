- %run - ![[2024-06-21#^1b3830]]
- %run /Users/malaithiru62@gmail.com/Databricks-Certified-Data-Engineer-Associate-main/Includes/Copy-Datasets
	- once I ran this, files were downloaded into the dbfs
	- a variable was available: dataset_bookstore which contained the path to the downloaded data
```
%sql
SELECT * from json.`${dataset.bookstore}/customers-json/export_001.json`
```
- surprisingly the \_ did not work in dataset_bookstore when tried in a sql cell
- when I tried to read the file using python's open and I gave the dbfs path the run gave me an error saying fnf
	- so I think we cannot read like this
- wild card reading allowed
```
%sql
SELECT * from json.`${dataset.bookstore}/customers-json/export_*.json`
```
- dir reading also allowed
```
%sql
SELECT * from json.`${dataset.bookstore}/customers-json`
```
- the above two reading methods are possible only if all the files that match have the same schema
- db previews only the first 1000 records
- when reading from multiple files, it is helpful to include builtin spark sql fns: `input_file_name()` - displays source file for each record
	- full path to the file is displayed
- we can read text based files such as JSON, CSV, TSV and txt formats as raw strings
![[Pasted image 20240713094504.png]]
- reading as text format only gives ***one STRING column*** in output
- we can also read the files as binary file, reading like this provides metadata about each file
	- total num of rows = total num of files
	- md cols includes path, mod time, length and truncated binary content
	- in the following code, I read a json file as binary
```
%sql

SELECT *, input_file_name() from binaryFile.`${dataset.bookstore}/customers-json`
```

```
%sql

SELECT *, input_file_name() from csv.`${dataset.bookstore}/books-csv`
```
- the above csv file was semi colon delimited, hence all data got displayed as a single string column
	- we cannot provide any option with the select statement
	- on alternative to display data correctly is using `USING`

```
%sql

CREATE TABLE xyz
(book_id STRING,
title string,
author string,
category string,
price DECIMAL)
USING CSV
OPTIONS(header = true,
delimiter = ';')
LOCATION Â 'dbfs:/mnt/demo-datasets/bookstore/books-csv'
```

- i gave wrong schema for the book_id(as int), spark did not throw any error
	- when I displayed data, the column was just null
- external tables cannot be replaced