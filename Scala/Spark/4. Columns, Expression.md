- retrieving columns from a dataframe:
```
val myColumn = df.col("Name") // there is a difference bw this and column method based column reference

df.select(myColumn).show()
```
- there are different ways to reference columns in scala spark
	- column names as strings, if we are using this - all column names must be specified in string only
	- various other ways which can be mixed and matched within the same call
		- `df.col("Name")`
		- `col("Name")`
			- as part of types module
		- `column("Name")`
			- as part of types module
		- `'Name`
			- to access like this, we need the `spark.implicits._` to be imported
			- looks like this is deprecated after a certain version of scala
			- but still it did work
		- `$"Name"`
			- even this column notation requires us to import the `spark.implicits._`
		- `expr("Name")`
			- as part of types module
		
- column objects are subtype of Expression
	- column objects themselves are the simples type of expression
```
val myFirstProperExpression = df.col("Weight_in_lbs") / 2.2
```
 - surprisingly the type of the above expression is Column
 - for renaming while selecting at least the following methods are available
	 - `as("new_name")` `alias("new_name")`
```
df.select($"Name",  
  col("Weight_in_lbs"),  
  round(col("Weight_in_lbs")/2.2,2).alias("Weight_in_kgs"),  
  expr("round(Weight_in_lbs/2.2,2) as Weight_in_kgs2").as("Naan_solra_name") 
).show(5)
```
- the value returned by col("Weight_in_lbs")/2.2 is not the same as value returned by expr("round(Weight_in_lbs/2.2,2) as Weight_in_kgs2")
	- expressions specified in expr are implemented differently than the column expression
- selectExpr method is used when there is a need for many expr call within a select
- adding and renaming column names:
```
df.withColumn("weight_in_kg", round(col("Weight_in_lbs")/2.2, 2))  
  .withColumnRenamed("Weight_in_lbs", "weight_in_lb").select("weight_in_kg", "weight_in_lb")
```
- to use or refer column names with spaces or hyphens in an expression, we use backticks within expr methods
	- not required with column methods
```
df.withColumnRenamed("Weight_in_lbs", "Weight in pounds").select("Weight in pounds").show(4)
df.withColumnRenamed("Weight_in_lbs", "Weight in pounds").selectExpr("`Weight in pounds`").show(3)
```
- to drop columns we have drop method which accept column names as strings
- to filter dataframes there is filter and where method
- not equal in scala spark =!=
- equality check in scala spark ===
- to represent strings inside expression, we need to use single quotes
- chaining filters together:
```
df.where((col("Origin") =!= "USA") && (col("Cylinders") === 4)).show()
df.where(col("Origin") =!= "USA").where(col("Cylinders") === 4).show()
df.where(col("Origin") =!= "USA" and col("Cylinders") === 4).show()
df.where((col("Origin") =!= "USA").and(col("Cylinders") === 4)).show()
df.where(col("Origin") =!= "USA" || col("Cylinders") === 4).show(3)
df.filter("Origin = 'USA' and Cylinders = 4").show(1)
```

- union:
```
df1.union(df.drop("_corrupt_record")).distinct().show(3)
```