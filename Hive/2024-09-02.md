
- hive does not store any physical data, it just points to data in hdfs
- built on write-once and read many concept
	- where as normal rdbms's are built on write-many and read many concept
- easy and cost effective scalability

- architecture of hive
	- UI
	- driver
	- compiler
	- execution engine
	- metastore
![[Pasted image 20240902084431.png]]
- UI is the component with which user directly interacts
	- Hive CLI
	- Web interface
	- thrift server
		- jdbc or odbc connection from an application
- driver
	- he mentioned driver converts the hive query to mr program with little help from the compiler
	- he also mentioned driver fetches required apis for the query
- compiler
	- has a role in the conversion of hive query to mr
	- also does semantic analysis of a program
	- eventually generates an execution plan with the help of metastore
- ms
	- small db
	- stores all structure information about tables, columns, partitions ,schema, serializer, deserializers
	- by default, hive uses built in derby sql server as ms
		- not in real time projects
		- because it provides single process storage
		- while using derby we cannot use two simultaneous instances of hive CLI
	- for real projects, we use mysql or other std db
		- these allow multiple instances of CLI
- execution engine
	- this component is connected with Hadoop fw
	- executes the plan created by the compiler
	- interacts with the namenode and resource manager to fetch the desired output data from the hdfs
		- resource manager: ultimate authority that allocates resources among all the applications in the system
		- node manager is the per machine fw agent, who is responsible for containers, monitoring their usage
		- name node: master node in hadoop hdfs that maintains and amanages the blocks present on the datanodes
			- controls access to files by clients
- ```CREATE DATABASE db1;```
	- running this multiple times errors out
- ```CREATE DATABASE IF NOT EXISTS d1;```
- `DESCRIBE database d1;`
	- db_name, comment, location, owner_name, owner type and parameters
	- the location for all databases is set by a property
	- any table that we create within a database, will be created as a subdirectory within the db's dir
	- d1.db folder created under hive warehouse directory
- comment can be provided while creating a database
	- ```CREATE DATABASE IF NOT EXISTS d2 comment 'this is a db';```
	- `describe database extended d2;`
- we can also create database with db properties
	- there are some predefined db properties linked with the db
	- `CREATE DATABASE IF NOT EXISTS d3 with dbproperties('creator'='thiru', 'date'='2024-08-08');`
	- to view these details we need to use `DESCRIBE DATABASE EXTENDED d3;`
	- stored as parameters
- `SHOW DATABASES;`
	- there will be a default database
	- when db detail not provided while creating a db, default db is used for that table
- `USE d2;`
	- any tables created without a database name, will be created under d2
- two types of tables: external and internal
	- differentiated by how the table md is stored
	- for internal table, hive is the sole owner of table's data and md
	- external: hive only responsible for table's md
	- dropping an internal table in hive then both table data and md is lost
	- dropping an external table erases only the md
- ```CREATE TABLE IF NOT EXISTS table1 (col1 string, col2 array<string>, col3 string, col4 int) row format delimited fields terminated by ',' collection items terminated by ':' lines terminated by '\' stored as textfile;```
	- by default file format is text file, he mentioned the stored as is to say format in which hive should store the file
	- by default row format is assumed to be delimited
	- fields terminated by default is control a
	- lines terminated by default is new line
	- default file format is text file
- there are other table creation clauses such as location,partition and table properties during table creation
- set hive.metastore.warehouse.dir;
	- this command displayed the config's value
	- /user/hive/warehouse
- ```CREATE TABLE IF NOT EXISTS table1 (col1 string, col2 array<string>, col3 string, col4 int) row format delimited fields terminated by ',' collection items terminated by ':' lines terminated by '\' stored as textfile location '/user/thiru/table3';```
	- now we have to link the md of data file
	- `load data local inpath'/path/to/file' into table table1; `
		- local keyword is used as the file is present in local file system and not in hdfs
		- local keyword to be omitted if data in hdfs
		- into is used to append the data
		- whereas overwrite can be used to overwrite the data