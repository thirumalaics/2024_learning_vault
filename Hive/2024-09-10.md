## Table Props contd
- how to make a table immutable
	- hive provides immutability against certain commands like insert
	- immutable table prop by default false
	- `CREATE TABLE TABLE3 (col1 STRING, col2 INT) row format delimited fields terminated by ',' lines terminated by '\n' stored as textfile tblproperties("immutable" = "true");`
	- the load data command works perfectly fine for this table
		- `load data local inpath '/home/jivesh/files/rank' into table table3;`
	- after the first load, the successive inserts start to fail is what he mentioned
	- but surprisingly, insert overwrite command works perfectly fine
		- `insert overwrite table table3 select * FROM Table2;`

- drop, truncate and purge
	- drop table - removes the data and md of a table for a managed table
		- for external only md is removed
		- `drop table table2;`
		- data goes to trash
			- this data can later be recovered using hadoop fnality
	- truncate - only data is removed from the table
		- `truncate table table4;`
	- purge is a table property
		- if set to true, and we drop a table the data will not go to trash it will be permanently deleted
		- `create table table7(col1 string, col2 int) row format delimited fields terminated by ','  lines terminated by '\n' stored as textfile tblproperties("auto.purge" = "true");`
		- data is completely gone when we drop or truncate, unrecoverable
- null format property
	- value passed to this property is passed as null value
	- empty fields(fields with missing values) in a file are not treated as nulls by default
	- `create table table4(col1 string, col2 int) row format delimited fields terminated by ',' lines terminated by '\n' stored as textfile tblproperties('serialization.null.format' = '');`
		- here empty strings are treated as nulls

## ACID/Txnal properties in Hive
- only orc file format supported for dmls - might have changed
- tables must be bucketed
- begin commit rollback features are also not supported
	- all operations are autocommit
- reading and writing to a acid table is only allowed in a session where txnal properties are true
	- only when the concurrency property is set to true in that session
- some properties that need to be enabled to create txnal table
	- `set hive.support.concurrency = true`
	- `set hive.enforce.bucketing = true`
	- `set hive.exec.dynamic.partition.mode = nonstrict`
	- `set hive.compactor.initiator.on = true`
	- `set hive.compactor.worker.threads = 1`
	- `set hive.txn.manager = org.apache.hadoop.hive.ql.lockmgr.DbTxnManager`
	- one more property needs to be set in the hive site xml
		- hive site xml found in hive installation folder
		- ```<configuration> <property> <name>hive.in.test</name><value>true</value></property></configuration>```
- `create table employee (emp_id int, emp_name string, emp_dep string) clustered by(emp_id) into 4 buckets stored as orc tblproperties('transactional' = 'true');`
- now row level insert is possible
- `insert into table employee VALUES(100, 'Jack','HR'), (101, 'Titi', 'Accounts);`
- `update employee set emp_dep = 'HR' where emp_id = 101;`
- we cannot update the bucketed column in hive
- `delete from employee where emp_id = 100;`